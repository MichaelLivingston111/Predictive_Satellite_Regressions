---
title: "Model_Creation_And_Selection"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Context: Marine exopolymeric substances have significant importance due to 
# their role in marine carbon dioxide sequestration (as particulate organic 
# carbon). This substances play a critical role in the efficiency of carbon 
# sequestration in our oceans, however, no large scale estimations currently 
# exist for these substances. Therefore, this project seeks to create reliable 
# statistical models to predict their concentrations from satellite sensors, 
# in order to derive large scale estimations on our oceans surface. This models 
# can also be applied to historical satellite data, in order to investigate 
# patterns or changes over time.



# This file contains the base code for selecting the optimal model based on a 
# series of available predictor variables and measured data sets.


# Upload required libraries:
```{r}

suppressMessages(library(ggplot2))
suppressMessages(library(caret))
suppressMessages(library(ggpubr))
suppressMessages(library(MuMIn))
suppressMessages(library(lme4))
suppressMessages(library(feather))
suppressMessages(library(arrow))
suppressMessages(library(dplyr))
suppressMessages(library(viridis))
suppressMessages(library(car))
suppressMessages(library(GGally))
suppressMessages(library(reshape2))
suppressMessages(library(PKNCA))

```



# Upload all the data, and sort into workable dataframes. There are two data 
# sets available. "Regional" and "Global" The Global dataset includes data from 
# the Arctic.
```{r}

# Create a function to read the csv files, index out the variables of interest, 
# and create another category.


Read_fn <- function(file) {
  
  data <- read.csv(file)  # Read the csv
  
  data <- data %>% 
    mutate(Bloom = if_else(Chl > 2.5, 1, 0))
  
  data <- data %>%  # Index out variables of interest
    select(TEP, Temperature, Season, Log_Chl, POC, Summer, 
           Winter, Bloom, Arctic, Area, Depth)
  
  data <- na.omit(data)
  

  return(data)
  
}


# Input required files into function:
regional_data <- Read_fn("MODEL_DATA.csv")  # Regional
global_data <- Read_fn("MODEL_DATA_GLOBAL.csv")  # Global

```



# Create a series of predictive models based off prior determinations. Start
# with a 'base' model using only one predictor, but sequentially add more 
# variables. 

# Here, we will use both linear regression and mixed effects predictive models:
```{r}

# *Note: Cannot use MLD with global models*

# Base models (linear by default):
Chl_model = lm(TEP ~ Log_Chl, data = global_data)  # Chl
POC_model = lm(TEP ~ POC, data = global_data)  # POC

# Create a list of all base linear models:
Base_LM_list <- list(Chl_model, POC_model)



# Linear models:
Chl_Temp_LM = lm(TEP ~ Temperature + Log_Chl, 
                   data = global_data)  # Chl, Temp

Chl_Temp_POC_LM = lm(TEP ~ Temperature + Log_Chl + POC, 
                  data = global_data) # Chl + Temp + POC

Chl_Temp_Bloom_LM = lm(TEP ~ Temperature + Log_Chl + Bloom, 
                   data = global_data)  # Chl, Temp

Chl_Temp_POC_Season_LM = lm(TEP ~ Temperature + 
                   Log_Chl + POC + Season, 
                   data = global_data)  # Chl + Temp + POC + Season

Chl_Temp_POC_Season_Bloom_LM = lm(TEP ~ Temperature + 
                   Log_Chl + POC + Season + Bloom, 
                   data = global_data)  # Chl + Temp + POC + Season + Bloom

Chl_Temp_POC_Bloom_Region_LM = lm(TEP ~ Temperature + 
                   Log_Chl + POC + Bloom + Arctic, 
                   data = global_data)  # Chl + Temp + POC + 
                                        # + Bloom + Area

# Create a list of all linear models:
LM_list <- list(Chl_Temp_LM,
                Chl_Temp_POC_LM, 
                Chl_Temp_Bloom_LM,
                Chl_Temp_POC_Season_LM,
                Chl_Temp_POC_Season_Bloom_LM, 
                Chl_Temp_POC_Bloom_Region_LM)


# Mixed effects models:

Chl_Temp_MEM = lmer(TEP ~ Temperature + Log_Chl + (1|Bloom), 
                    data = global_data)  # Chl + Temp

Chl_Temp_POC_MEM = lmer(TEP ~ Temperature + Log_Chl + POC + Arctic + (1|Bloom), 
                     data = global_data)  # Chl + MLD + POC + Area

Chl_Temp_POC_Season_MEM = lmer(TEP ~ Temperature + Log_Chl + POC + Summer + 
                    (1|Bloom), data = global_data)  # Chl + MLD + POC + Season

# Create a list of all mixed effects models:
MEM_list <- list(Chl_Temp_MEM, 
                 Chl_Temp_POC_MEM, 
                 Chl_Temp_POC_Season_MEM)

```



# We now have a series of predictive models, but not all of them are likely 
# appropriate (i.e. they do not satisfy linear modelling assumptions). Here, 
# we will run a series of tests, and elimiate any model that does not satisfy 
# the requirements.

# Assumption of multi-collinearity:
```{r}

# Create a function to identify excess multi-collinearity (VIF test) for each 
# model:


VIF_fn <- function(model) {
  
  score <- car::vif(model)
  score <- max(score)  # Any score >5 will be removed as unacceptable
  
  return(score)
  
}


# Apply the function to identify multi-collinearity:
lapply(LM_list, VIF_fn)

lapply(MEM_list, VIF_fn)

```



# Assumption of normaily in residual distributions:
```{r}

# Create a function to identify non-normality in model residual distribution
# (Shapiro-Wilks test) for each model:


Norm_fn <- function(model) {
  
  norm <- shapiro.test(resid(model))  # scores < 0.05 will be removed
  
  return(norm)
  
}


# Apply the function to identify multi-collinearity:
lapply(LM_list, Norm_fn)
lapply(MEM_list, Norm_fn)

```



# Now, we can drop any models that did not pass the above tests:
```{r}

# Create a new list with only the valid models
Valid_models <- list(LM_list[[3]], LM_list[[4]], LM_list[[6]],
                     MEM_list[[1]], MEM_list[[2]])


# Compare models with AIC selection criteria. Will output preffered model:
AIC(Valid_models)
AIC(LM_list[[3]], LM_list[[4]], LM_list[[6]], MEM_list[[1]], MEM_list[[2]])


# View a summary for the preferred model:
summary(LM_list[[6]])


```


# Build a funciton that creates a set of plots to visualize statistical 
# assumptions for a given model:
```{r}


ModelVal <- function(model, data){
  
    # Get the model residuals and predictions:
    resid <- resid(model)  # residuals
    predicts <- predict(model)  # predictions
    
    

    # Plot the distribution of the model residuals:
    Histo <- ggplot(data, aes(resid)) + 
      geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
      xlab("Residuals") +
      ylab("Count") +
      theme_pubr()
    
    
    # QQplots:
    QQ <- ggplot(data, aes(sample = resid)) +
      stat_qq() + stat_qq_line() +
      xlab("Theoretical quantiles") +
      ylab("Sample Quantiles") +
      theme_pubr()
    
    
    # Residual plot:
    Res <- ggplot(data, aes(predicts, resid)) +
        geom_point(alpha = 0.5)  +
        geom_abline(slope = 0, intercept = 0, linetype = "dashed") +
        theme_pubr()
    
    
    # Scatter:
    Val <- ggplot(global_data, aes(TEP, predicts)) +
        geom_point(alpha = 0.5) +
        geom_abline(slope = 1, intercept = 0, linetype = "dashed") +  #1:1 line
        theme_pubr()
    
    
    # Arrange plots:
    plots <- ggarrange(QQ, Histo, Res, Val, ncol = 2, nrow = 2)
    
    return(plots)

}


ModelVal(LM_list[[6]], global_data)


```


# Perform cross validation techniques to assess the predictive accuracy of each 
# suitable model on new data. A function below employs both "Leave one out 
# cross validation" and "K-fold cross validation" techniques:
```{r}

# Define the cross validation functions:
train.control.LOOCV <- trainControl(method = "LOOCV")
train.control.KFOLD <- trainControl(method = "repeatedcv", 
                                    number = 10, repeats = 10)
  
  

# Train the selected model using train control functions above:
preffered_model_LOOCV <- train(TEP ~ Log_Chl + Temperature + POC + Arctic + Bloom, 
                         data = global_data, method = "lm",
                         trControl = train.control.LOOCV)

preffered_model_KFOLD <- train(TEP ~ Log_Chl + Temperature + POC + Arctic + Bloom, 
                         data = global_data, method = "lm",
                         trControl = train.control.KFOLD)
  
  

# Create a function to calculate prediction accuracy for the above model:

ModelCrossVal <- function(model, data){
  
  predictions <- predict(model)
  
  mae <- MAE(predictions, data$TEP)  # Mean absolute error
  rmse <- RMSE(predictions, data$TEP)  # Root mean square error
  rsq <- summary(model)$r.squared  # R squared
  
  acc <- c(mae, rmse, rsq)
  
  return(acc)

  }



# Create a function to plots cross validation results for the above model and 
# cross validation techniques:

CrossValPlot <- function(model, data){
  
  data$Predictions <- predict(model)
  
  # Calculate Rsqaured between predicted and true values to annotate:
  Rsq <- summary(lm(Predictions ~ TEP, data = data))$r.squared
  Rsq <- format(round(Rsq, 2), nsmall = 2)
  
  # Calculate MAE between predicted and true values to annotate:
  MAE <- MAE(data$Predictions, data$TEP)
  MAE <- format(round(MAE, 2), nsmall = 2)
  
  crossvalplot <- ggplot(data, aes(TEP, Predictions, color = Area)) +
    geom_point(alpha = 0.7, size = 2) +
    ylab("Predicted TEP") +
    xlab("Measured TEP") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    #scale_color_manual(values = c("royalblue", "black")) +
    #scale_color_viridis() +
    #facet_wrap(~Season) +
    #geom_label(aes(25, 130, label=paste("R squared: ", Rsq,
                      # "\nMean absolute error: ", MAE)), color = 'black') +
    theme(legend.title = element_blank()) +
    theme_bw()
  
  return(crossvalplot)
}


# Apply the functions to calculate and visualize accuracy metrics:
ModelCrossVal(preffered_model_KFOLD, global_data)
CrossValPlot(preffered_model_KFOLD, global_data)

```


# Redefine the optimal model for export to another file:
```{r}

Applied_model <- LM_list[[6]]

summary(Applied_model)

```






