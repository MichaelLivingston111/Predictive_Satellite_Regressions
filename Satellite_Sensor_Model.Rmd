---
title: "Satellite_Sensor_Model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Upload required libraries:
```{r}

suppressMessages(library(ggplot2))
suppressMessages(library(caret))
suppressMessages(library(ggpubr))
suppressMessages(library(MuMIn))
suppressMessages(library(lme4))
suppressMessages(library(feather))
suppressMessages(library(arrow))
suppressMessages(library(dplyr))
suppressMessages(library(viridis))
suppressMessages(library(grid))
suppressMessages(library(car))
suppressMessages(library(GGally))
suppressMessages(library(reshape2))
suppressMessages(library(ggrepel))
suppressMessages(library(mgcv))
suppressMessages(library(visreg))

```


# Upload all the data, and sort into workable dataframes:
```{r}

# Upload the data from a total data file:
total_data <- read.csv("Total_Sat_Data_All_Var.csv")

# Specify all the relevant variables:
data <- total_data %>% select(TEP, Temperature, Season, Log_Chl, POC, Avg_PAR)

```


# This code chunk is only deisgned to give us an indication of the most important/influential model parameters by perfroming a stepwise regression selection. This technique will select only the variables that significantly improve the model performance. 
```{r}

# Define intercept-only model:
intercept_only <- lm(TEP ~ 1, data = data)  

# Define model with all predictors
all <- lm(TEP ~ ., data = data)

# Perform backward stepwise regression
backward <- step(all, direction ='backward', scope = formula(all), trace=0)

# #xamine the coefficients:
backward$coefficients  

```


# Create a series of predictive models based off the informaiton from stepwise selection above. We will start with a 'base' model using only one predictor, but sequentially add more variables:
```{r}

# Base model:
base_model = lm(TEP ~ Log_Chl, data = data)

# Model 2:
model_2 = lm(TEP ~ Temperature + Log_Chl, data = data)

# Model 3:
model_3 = lm(TEP ~ Temperature + Log_Chl + POC, data = data)

# Candidate model:
Satellite_lm = lm(TEP ~ Temperature + Log_Chl + POC + Season, data = data)

# Potential model:
Satellite_PAR = lm(TEP ~ Temperature + Log_Chl + POC + Avg_PAR, data = data)

```


# May need to eliminate variables to avoid multicollinearity. Check for this vby examining the variance inflation factors.
```{r}


car::vif(model_2)
car::vif(model_3)
car::vif(Satellite_lm)
car::vif(Satellite_PAR)

# No concerns about multicollinearity....

```


# What model is prefferred? Check AIC and AICc scores for model selection:
```{r}

AIC(Satellite_PAR, Satellite_lm, base_model, model_2, model_3)
AICc(Satellite_PAR, Satellite_lm, base_model, model_2, model_3)

# The candidate model ('Satellite lm') is the preferred model based of AIC scores.

```


# In order to practically apply these models, we need to check certain assumptions: Equal variance and normal distribution of model residuals:
```{r}

# Get the model residuals:
data$resid1 <- resid(Satellite_PAR)  # residuals
data$predict1 <- predict(Satellite_PAR)  # predictions

data$resid2 <- resid(Satellite_lm)  
data$predict2 <- predict(Satellite_lm) 

data$resid3 <- resid(base_model)  
data$predict3 <- predict(base_model) 

data$resid4 <- resid(model_2)  
data$predict4 <- predict(model_2) 

data$resid5 <- resid(model_3)  
data$predict5 <- predict(model_3) 




# Residual, Cooks distance plots:
plot(Satellite_PAR)  
plot(Satellite_lm)
plot(base_model)
plot(model_2)
plot(model_3)




```


# Check for normality in the residuals - Plot histograms of their distributions:
```{r}

# Plot the distribution of the model residuals:
H_model1 <- ggplot(data = data, aes(resid1)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model2 <- ggplot(data = data, aes(resid2)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model3 <- ggplot(data = data, aes(resid3)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model4 <- ggplot(data = data, aes(resid4)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model5 <- ggplot(data = data, aes(resid5)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()



ggarrange(H_model1, H_model2, H_model3, H_model4, H_model5)


# Use the Shapiro-Wilks test to test for normality distributions in the residuals:
shapiro.test(data$resid1) 
shapiro.test(data$resid2) 
shapiro.test(data$resid3) 
shapiro.test(data$resid4) 
shapiro.test(data$resid5) 

```


# Perform a 30x cross validation to assess the accuracy of these models on new data. This is done by splitting the data into a 95% training set (in which the model is trained on), and 5% testing set (in which the model is tested on). Repeat this process 30x to cover the entire dataset and determine an estimation of the predictive ability for each model.
```{r}

# Containers for the predictions and accuracy measurements:

sample_train <- NULL

# Theoretical model:
Sat_lmer_predict <- NULL
Sat_lmer_RMSE <- NULL
Sat_lmer_MAE <- NULL

# Candidate model:
Sat_lm_predict <- NULL
Sat_lm_RMSE <- NULL
Sat_lm_MAE <- NULL

# Base model:
base_predict <- NULL
base_RMSE <- NULL
base_MAE <- NULL

# Model 2:
model_2_predict <- NULL
model_2_RMSE <- NULL
model_2_MAE <- NULL

# Model 3:
model_3_predict <- NULL
model_3_RMSE <- NULL
model_3_MAE <- NULL


# Loop through model prediction and perform 25x cross validation. 
# The model is trained on 95% of the data, and validated on the other 5%

for (i in 1:30) {
  
  #Creating a re-sampled data set from the total data:
  training.samples <- createDataPartition(data$TEP, p = 0.95, list = FALSE)
  train.data1  <- data[training.samples, ]  # Training set
  test.data1 <- data[-training.samples, ]  # Testing set
  
  
  # Running the models and creating predictions, accuracy metrics on the partitioned training data:
  
  # Ideal model::
  #Sat_lmer_CV<- lmer(TEP ~ Log_Chl + Temperature + POC + (1|Season), data = train.data1) 
  Sat_lmer_CV<- lm(TEP ~ Log_Chl + Temperature + POC + Avg_PAR, data = train.data1) 
  
  
  # Linear model:
  Sat_lm_CV<- lm(TEP ~ Log_Chl + Temperature + POC, data = train.data1) 
  
  # Base model:
  base_CV<- lm(TEP ~ Log_Chl, data = train.data1) 
  
  # model 2:
  model_2_CV<- lm(TEP ~ Log_Chl + Temperature, data = train.data1) 
  
  # model 3:
  model_3_CV<- lm(TEP ~ Log_Chl + Temperature + POC, data = train.data1) 
  
  
  # Model 'true' training points, applies to each model:
  sample_train <- c(sample_train, test.data1$TEP)
  
  
  
  # PREDICTIONS AND ERROR ESTIMATIONS (in the following order):
  
  # Model name
  # Predictions
  # Root mean square error of residuals
  # Mean absolute error of residuals
  
  
  # Theoretical model:
  Sat_lmer_predict <- c(Sat_lmer_predict, predict(Sat_lmer_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))
  
  Sat_lmer_RMSE <- c(Sat_lmer_RMSE, RMSE(Sat_lmer_predict, sample_train))  # RMSE
  Sat_lmer_MAE <- c(Sat_lmer_MAE, MAE(Sat_lmer_predict, sample_train))  # MAE
  

  # Candidate model:
  Sat_lm_predict <- c(Sat_lm_predict, predict(Sat_lm_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE)) 
  Sat_lm_RMSE <- c(Sat_lm_RMSE, RMSE(Sat_lm_predict, sample_train))  # RMSE
  Sat_lm_MAE <- c(Sat_lm_MAE, MAE(Sat_lm_predict, sample_train))  # MAE
  
  
  # Base model:
  base_predict <- c(base_predict, predict(base_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))
  base_RMSE <- c(base_RMSE, RMSE(base_predict, sample_train))  # RMSE
  base_MAE <- c(base_MAE, MAE(base_predict, sample_train))  # MAE
  
  
  # Model 2:
  model_2_predict <- c(model_2_predict, predict(model_2_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE)) 
  model_2_RMSE <- c(model_2_RMSE, RMSE(model_2_predict, sample_train))  # RMSE
  model_2_MAE <- c(model_2_MAE, MAE(model_2_predict, sample_train))  # MAE
  
  
  # Model 3:
  model_3_predict <- c(model_3_predict, predict(model_3_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))
  model_3_RMSE <- c(model_3_RMSE, RMSE(model_3_predict, sample_train))  # RMSE
  model_3_MAE <- c(model_3_MAE, MAE(model_3_predict, sample_train))  # MAE
  
  
  
}


# The above loop generated 5 x 30 different regression models, and derived model predictions on validation data, plus estimates of their accuracies (RMSE, MAE). 

# Combine the predictions into a dataframe:
predictions <- cbind(Sat_lmer_predict, Sat_lm_predict, 
                     base_predict, model_2_predict, model_3_predict)
predictions <- as.data.frame(predictions)  # as a data frame

```


# Plot the results of the cross validation:
```{r}

Figure <- ggplot(predictions, aes(x = sample_train)) +
    #geom_point(aes(y = Sat_lm_predict), alpha = 1, colour = "blue") +
    geom_point(aes(y = model_2_predict), alpha = 1, colour = "blue") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    ggtitle("") +
    ylim(0, 150) +
    xlim(0, 150) +
    ylab("Predicted TEP") +
    xlab("Measured TEP") +
    theme_pubr() +
    theme(plot.title=element_text(size=8,face="bold"))


Figure

```


# Compare all the model accuracies using mean absolute errors (MAE). The MAE is essentially the average difference between predicted and true values.
```{r, fig.width = 10, fig.height = 6}

# Get the MAE:
MAE <- cbind(base_MAE, model_2_MAE, model_3_MAE, Sat_lm_MAE, Sat_lmer_MAE)
MAE <- as.data.frame(MAE)


# Reconstruct the dataframe:
MAE_dff <- melt(MAE,  variable.name = 'MAE')


# Visualize the model accuracies with a boxplot of MAE values:
MAE_box <- ggplot(MAE_dff, aes(x = MAE, y = value)) +
  geom_boxplot(fill = "blue", alpha = 0.5, outlier.shape = NA) +
  ylab("") +
  xlab("") +
  ylim(7, 18) +
  theme_pubr() +
  coord_flip()


MAE_box

```



# Now lets try predicting an entire independent research expedition:
```{r}

# Reselect the data with an extra group parameter:
data <- total_data %>% select(TEP, Temperature, Season, Log_Chl, POC, 
                              Avg_PAR, SST, Region, Summer_2021_LP, Spring_2021_LP, Spring_2019_LP, Summer_2019_LP)


# Split the data into the expedition(s) of interest:
total_split_summer <- split(data, data$Summer_2021_LP) 
total_split_spring <- split(data, data$Spring_2021_LP)
total_split_spring1 <- split(data, data$Spring_2019_LP)
total_split_summer1 <- split(data, data$Summer_2019_LP)


data_summer_2021 <- total_split_summer$Y  # Summer 2021 expedition
data_Else <- total_split_summer$N  # All else data

data_spring_2021 <- total_split_spring$Y  # Spring 2021 expedition
data_Else2 <- total_split_spring$N  # All else data


data_spring_2019 <- total_split_spring1$Y  # Spring 2019 expedition
data_Else19 <- total_split_spring1$N  # All else data

data_summer_2019 <- total_split_summer1$Y  # Summer 2019 expedition
data_ElseSum19 <- total_split_summer1$N  # All else data



# Create two models to predict each expeditions value with the rest of the dataset:
Showcase_model_summer <- lm(TEP ~ Log_Chl + Temperature + POC + Season, data = data_Else)
Showcase_model_spring <- lm(TEP ~ Log_Chl + Temperature + POC + Season, data = data_Else2)
Showcase_model_spring1 <- lm(TEP ~ Log_Chl + Temperature + POC + Season, data = data_Else19)
Showcase_model_summer1 <- lm(TEP ~ Log_Chl + Temperature + POC + Season, data = data_ElseSum19)


# Make the predictions
data_summer_2021$predict = predict(Showcase_model_summer, data_summer_2021, type = 'response')  # Summer 2021
data_Else$predict = predict(Showcase_model_summer, data_Else, type = 'response')


data_spring_2021$predict = predict(Showcase_model_spring, data_spring_2021, type = 'response')  # Spring 2021
data_Else2$predict = predict(Showcase_model_spring, data_Else2, type = 'response')


data_spring_2019$predict = predict(Showcase_model_spring1, data_spring_2019, type = 'response')  # Spring 2019
data_Else19$predict = predict(Showcase_model_spring1, data_Else19, type = 'response')


data_summer_2019$predict = predict(Showcase_model_summer1, data_summer_2019, type = 'response')  # Summer 2019
data_ElseSum19$predict = predict(Showcase_model_summer1, data_ElseSum19, type = 'response')


# Name the stations that will be predicted:
Name = c("P1", "P4", "P12", "P16", "P20", "P26")


# Plot the results:
CV <- ggplot() +
  
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +  # 1:1 reference line
  
  #geom_point(aes(x = data_Else2$TEP, y = data_Else2$predict), colour = 'black', alpha = 0.3) +  # Training data

  geom_point(aes(x = data_spring_2021$TEP, data_spring_2021$predict), colour = 'blue', fill = 'blue', pch = 1) +  # Test data
  
  geom_point(aes(x = data_summer_2021$TEP, data_summer_2021$predict), colour = 'red', fill = 'red', pch = 1) +  # Test data
  
  geom_point(aes(x = data_spring_2019$TEP, data_spring_2019$predict), colour = 'blue', fill = 'blue', pch = 21) +  # Test data
  
  geom_point(aes(x = data_summer_2019$TEP, data_summer_2019$predict), colour = 'red', fill = 'red', pch = 21) +  # Test data
  
  #geom_label_repel(aes(x = data_spring_2021$TEP, data_spring_2021$predict, label = Name),  # Labels
                  #box.padding   = 0.15, 
                  #point.padding = 0.15,
                  #segment.linetype = 1,
                  #segment.color = 'blue', 
                  #max.overlaps = Inf) +


  theme_classic() +
  xlab("Measured TEP") +
  ylab("Predicted TEP") +
  ylim(0, 160) +
  xlim(0, 160)
  


CV



```


# Next, lets create a et of general additive models for the sole purpose of using the vis.gam function to create a nice visualization of the model.
```{r}

# Create the models:
model_gam = gam(TEP ~ s(Temperature) + (Log_Chl) + (log(POC)), data = data)

model_lm = gam(TEP ~ (Temperature) + (Log_Chl) + log(POC) +(Season), data = data)

```

# GAM residuals
```{r}

gam.check(model_lm)

summary(model_lm)
```

# Smoothing terms
```{r}

par(mfrow = c(1, 3), omi = c(0, 0, 0.5, 0))
plot(model_gam, residuals = TRUE, pch = 1)
title(outer = TRUE, main = "", font.main = 1)


```

# Residuals for each predictor:
```{r}
resid <- resid(model_lm)
fit <- predict(model_lm)

par(mfrow = c(2, 2), mar = c(4, 4, 1, 1))
plot(resid ~ fit); abline(h = 0, lty = 2)
plot(resid ~ data$Log_Chl); abline(h = 0, lty = "dashed")
plot(resid ~ data$Temperature); abline(h = 0, lty = "dashed")
plot(resid ~ data$POC); abline(h = 0, lty = "dashed")
abline(h = 0, lty = "dashed")


```

# Modify the vis.gam function to include my colours! This is a very large chunk of code taken from the mgcv package. I have ismply added in a line of code to create a new colour palette that I find is more sutiable for this dataset.
```{r}
jet.colors <-colorRampPalette(c("#00007F", "blue", "#007FFF", "cyan",
                                "#7FFF7F", "yellow", "#FF7F00", "red", "#7F0000"))

magma.colors <-colorRampPalette(c("#4B2991", "#5C2995", "#692A99", "#872CA2", "#952EA0", "#B1339E", "#CA3C97",
                                  "#D44292", "#EA4F88", "#F2637F", "#F66D7A", "#F98477", "#F79C79",
                                "#F6A97A", "#EFCC98", "#EED19C", "#EDD9A3"))

myvis.gam <- function (x, view = NULL, cond = list(), n.grid = 30, too.far = 0, 
          col = NA, color = "heat", contour.col = NULL, se = -1, type = "link", 
          plot.type = "persp", zlim = NULL, nCol = 50, ...) 
{
  fac.seq <- function(fac, n.grid) {
    fn <- length(levels(fac))
    gn <- n.grid
    if (fn > gn) 
      mf <- factor(levels(fac))[1:gn]
    else {
      ln <- floor(gn/fn)
      mf <- rep(levels(fac)[fn], gn)
      mf[1:(ln * fn)] <- rep(levels(fac), rep(ln, fn))
      mf <- factor(mf, levels = levels(fac))
    }
    mf
  }
  dnm <- names(list(...))
  v.names <- names(x$var.summary)
  if (is.null(view)) {
    k <- 0
    view <- rep("", 2)
    for (i in 1:length(v.names)) {
      ok <- TRUE
      if (is.matrix(x$var.summary[[i]])) 
        ok <- FALSE
      else if (is.factor(x$var.summary[[i]])) {
        if (length(levels(x$var.summary[[i]])) <= 1) 
          ok <- FALSE
      }
      else {
        if (length(unique(x$var.summary[[i]])) == 1) 
          ok <- FALSE
      }
      if (ok) {
        k <- k + 1
        view[k] <- v.names[i]
      }
      if (k == 2) 
        break
    }
    if (k < 2) 
      stop("Model does not seem to have enough terms to do anything useful")
  }
  else {
    if (sum(view %in% v.names) != 2) 
      stop(paste(c("view variables must be one of", v.names), 
                 collapse = ", "))
    for (i in 1:2) if (!inherits(x$var.summary[[view[i]]], 
                                 c("numeric", "factor"))) 
      stop("Don't know what to do with parametric terms that are not simple numeric or factor variables")
  }
  ok <- TRUE
  for (i in 1:2) if (is.factor(x$var.summary[[view[i]]])) {
    if (length(levels(x$var.summary[[view[i]]])) <= 1) 
      ok <- FALSE
  }
  else {
    if (length(unique(x$var.summary[[view[i]]])) <= 1) 
      ok <- FALSE
  }
  if (!ok) 
    stop(paste("View variables must contain more than one value. view = c(", 
               view[1], ",", view[2], ").", sep = ""))
  if (is.factor(x$var.summary[[view[1]]])) 
    m1 <- fac.seq(x$var.summary[[view[1]]], n.grid)
  else {
    r1 <- range(x$var.summary[[view[1]]])
    m1 <- seq(r1[1], r1[2], length = n.grid)
  }
  if (is.factor(x$var.summary[[view[2]]])) 
    m2 <- fac.seq(x$var.summary[[view[2]]], n.grid)
  else {
    r2 <- range(x$var.summary[[view[2]]])
    m2 <- seq(r2[1], r2[2], length = n.grid)
  }
  v1 <- rep(m1, n.grid)
  v2 <- rep(m2, rep(n.grid, n.grid))
  newd <- data.frame(matrix(0, n.grid * n.grid, 0))
  for (i in 1:length(x$var.summary)) {
    ma <- cond[[v.names[i]]]
    if (is.null(ma)) {
      ma <- x$var.summary[[i]]
      if (is.numeric(ma)) 
        ma <- ma[2]
    }
    if (is.matrix(x$var.summary[[i]])) 
      newd[[i]] <- matrix(ma, n.grid * n.grid, ncol(x$var.summary[[i]]), 
                          byrow = TRUE)
    else newd[[i]] <- rep(ma, n.grid * n.grid)
  }
  names(newd) <- v.names
  newd[[view[1]]] <- v1
  newd[[view[2]]] <- v2
  if (type == "link") 
    zlab <- paste("linear predictor")
  else if (type == "response") 
    zlab <- type
  else stop("type must be \"link\" or \"response\"")
  fv <- predict.gam(x, newdata = newd, se.fit = TRUE, type = type)
  z <- fv$fit
  if (too.far > 0) {
    ex.tf <- exclude.too.far(v1, v2, x$model[, view[1]], 
                             x$model[, view[2]], dist = too.far)
    fv$se.fit[ex.tf] <- fv$fit[ex.tf] <- NA
  }
  if (is.factor(m1)) {
    m1 <- as.numeric(m1)
    m1 <- seq(min(m1) - 0.5, max(m1) + 0.5, length = n.grid)
  }
  if (is.factor(m2)) {
    m2 <- as.numeric(m2)
    m2 <- seq(min(m1) - 0.5, max(m2) + 0.5, length = n.grid)
  }
  if (se <= 0) {
    old.warn <- options(warn = -1)
    av <- matrix(c(0.5, 0.5, rep(0, n.grid - 1)), n.grid, 
                 n.grid - 1)
    options(old.warn)
    max.z <- max(z, na.rm = TRUE)
    z[is.na(z)] <- max.z * 10000
    z <- matrix(z, n.grid, n.grid)
    surf.col <- t(av) %*% z %*% av
    surf.col[surf.col > max.z * 2] <- NA
    if (!is.null(zlim)) {
      if (length(zlim) != 2 || zlim[1] >= zlim[2]) 
        stop("Something wrong with zlim")
      min.z <- zlim[1]
      max.z <- zlim[2]
    }
    else {
      min.z <- min(fv$fit, na.rm = TRUE)
      max.z <- max(fv$fit, na.rm = TRUE)
    }
    surf.col <- surf.col - min.z
    surf.col <- surf.col/(max.z - min.z)
    surf.col <- round(surf.col * nCol)
    con.col <- 1
    if (color == "heat") {
      pal <- heat.colors(nCol)
      con.col <- 3
    }
    else if (color == "topo") {
      pal <- topo.colors(nCol)
      con.col <- 2
    }
    else if (color == "cm") {
      pal <- cm.colors(nCol)
      con.col <- 1
    }
    else if (color == "terrain") {
      pal <- terrain.colors(nCol)
      con.col <- 2
    }
    else if (color == "gray" || color == "bw") {
      pal <- gray(seq(0.1, 0.9, length = nCol))
      con.col <- 1
    }
    ### customized here
    else if (color == 'jet') {
      pal <- jet.colors(nCol)
      con.col = 1
    }
    ### customized here <- MINE
    else if (color == 'magma') {
      pal <- magma.colors(nCol)
      con.col = 1
    }
    ####
    else stop("color scheme not recognised")
    if (is.null(contour.col)) 
      contour.col <- con.col
    surf.col[surf.col < 1] <- 1
    surf.col[surf.col > nCol] <- nCol
    if (is.na(col)) 
      col <- pal[as.array(surf.col)]
    z <- matrix(fv$fit, n.grid, n.grid)
    if (plot.type == "contour") {
      stub <- paste(ifelse("xlab" %in% dnm, "", ",xlab=view[1]"), 
                    ifelse("ylab" %in% dnm, "", ",ylab=view[2]"), 
                    ifelse("main" %in% dnm, "", ",main=zlab"), ",...)", 
                    sep = "")
      if (color != "bw") {
        txt <- paste("image(m1,m2,z,col=pal,zlim=c(min.z,max.z)", 
                     stub, sep = "")
        eval(parse(text = txt))
        txt <- paste("contour(m1,m2,z,col=contour.col,zlim=c(min.z,max.z)", 
                     ifelse("add" %in% dnm, "", ",add=TRUE"), ",...)", 
                     sep = "")
        eval(parse(text = txt))
      }
      else {
        txt <- paste("contour(m1,m2,z,col=1,zlim=c(min.z,max.z)", 
                     stub, sep = "")
        eval(parse(text = txt))
      }
    }
    else {
      stub <- paste(ifelse("xlab" %in% dnm, "", ",xlab=view[1]"), 
                    ifelse("ylab" %in% dnm, "", ",ylab=view[2]"), 
                    ifelse("main" %in% dnm, "", ",zlab=zlab"), ",...)", 
                    sep = "")
      if (color == "bw") {
        op <- par(bg = "white")
        txt <- paste("persp(m1,m2,z,col=\"white\",zlim=c(min.z,max.z) ", 
                     stub, sep = "")
        eval(parse(text = txt))
        par(op)
      }
      else {
        txt <- paste("persp(m1,m2,z,col=col,zlim=c(min.z,max.z)", 
                     stub, sep = "")
        eval(parse(text = txt))
      }
    }
  }
  else {
    if (color == "bw" || color == "gray") {
      subs <- paste("grey are +/-", se, "s.e.")
      lo.col <- "gray"
      hi.col <- "gray"
    }
    else {
      subs <- paste("red/green are +/-", se, "s.e.")
      lo.col <- "green"
      hi.col <- "red"
    }
    if (!is.null(zlim)) {
      if (length(zlim) != 2 || zlim[1] >= zlim[2]) 
        stop("Something wrong with zlim")
      min.z <- zlim[1]
      max.z <- zlim[2]
    }
    else {
      z.max <- max(fv$fit + fv$se.fit * se, na.rm = TRUE)
      z.min <- min(fv$fit - fv$se.fit * se, na.rm = TRUE)
    }
    zlim <- c(z.min, z.max)
    z <- fv$fit - fv$se.fit * se
    z <- matrix(z, n.grid, n.grid)
    if (plot.type == "contour") 
      warning("sorry no option for contouring with errors: try plot.gam")
    stub <- paste(ifelse("xlab" %in% dnm, "", ",xlab=view[1]"), 
                  ifelse("ylab" %in% dnm, "", ",ylab=view[2]"), ifelse("zlab" %in% 
                                                                         dnm, "", ",zlab=zlab"), ifelse("sub" %in% dnm, 
                                                                                                        "", ",sub=subs"), ",...)", sep = "")
    txt <- paste("persp(m1,m2,z,col=col,zlim=zlim", ifelse("border" %in% 
                                                             dnm, "", ",border=lo.col"), stub, sep = "")
    eval(parse(text = txt))
    par(new = TRUE)
    z <- fv$fit
    z <- matrix(z, n.grid, n.grid)
    txt <- paste("persp(m1,m2,z,col=col,zlim=zlim", ifelse("border" %in% 
                                                             dnm, "", ",border=\"black\""), stub, sep = "")
    eval(parse(text = txt))
    par(new = TRUE)
    z <- fv$fit + se * fv$se.fit
    z <- matrix(z, n.grid, n.grid)
    txt <- paste("persp(m1,m2,z,col=col,zlim=zlim", ifelse("border" %in% 
                                                             dnm, "", ",border=hi.col"), stub, sep = "")
    eval(parse(text = txt))
  }
}
```


# Visualize the model!!
```{r}

myvis.gam(model_lm, view = c("Log_Chl", "Temperature"), 
          theta = -40, type = "response",  color = 'magma',
          n.grid=50, border = NA, too.far = 0)

```

# BEAUTIFUL!


