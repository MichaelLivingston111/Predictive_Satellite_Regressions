---
title: "Satellite_Sensor_Model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Upload required libraries:
```{r}

suppressMessages(library(ggplot2))
suppressMessages(library(caret))
suppressMessages(library(ggpubr))
suppressMessages(library(MuMIn))
suppressMessages(library(lme4))
suppressMessages(library(feather))
suppressMessages(library(arrow))
suppressMessages(library(dplyr))
suppressMessages(library(viridis))
suppressMessages(library(grid))
suppressMessages(library(car))

```


# Upload all the data, and sort into workable dataframes:
```{r}

# Upload the data from a total data file:
total_data <- read.csv("Total_Sat_Data_All_Var.csv")

# Specify all the relevant variables:
data <- total_data %>% select(TEP, Temperature, Season, Log_Chl, POC, Avg_PAR)

```


# Step-wise Regressions models: Both forward and backward sequences for both types of models:
```{r}

# Define intercept-only model
intercept_only <- lm(TEP ~ 1, data = data)  # linear
intercept_lmer <- lmer(TEP ~ 1 + (1|Season), data = data)  # mixed effects

# Define model with all predictors
all <- lm(TEP ~ ., data = data)  # linear
all_lmer <- lmer(TEP ~ . + (1|Season), data = data)  # mixed effects

```


# Perform forward stepwise regression:
```{r}
forward <- step(intercept_only, direction='forward', scope=formula(all), trace=0)
forward$anova
forward$coefficients

plot(forward$residuals ~ forward$fitted.values)

```


# Perform backward stepwise regression
```{r}

# Perform backward stepwise regression
backward <- step(all, direction ='backward', scope = formula(all), trace=0)
backward$anova
backward$coefficients

plot(backward$residuals ~ backward$fitted.values)


# Both model selection techniques coverged on the same set of variables, outlined below.
```



# Specify a ideal mixed effects and linear models based on the variable selections above:
```{r}

# Ideal satellite model
Satellite_All_lmer = lmer(TEP ~ Temperature + Log_Chl + POC + Avg_PAR + (1|Season), data = data)
summary(Satellite_All_lmer)
r.squaredGLMM(Satellite_All_lmer)

# reduced satellite model
Satellite_lmer = lmer(TEP ~ Temperature + Log_Chl + POC + (1|Season), data = data)
summary(Satellite_lmer)
r.squaredGLMM(Satellite_lmer)

Satellite_lm = lm(TEP ~ Temperature + Log_Chl + POC + Avg_PAR, data = data)
summary(Satellite_lm)

```


# May need to eliminate variables to avoid multicollinearity:
```{r}

car::vif(Satellite_All_lmer)
car::vif(Satellite_lmer)
car::vif(Satellite_lm)

# No concerns about multicollinearity....

```


# What model is prefferred? Check AIC and AICc:
```{r}

AIC(Satellite_All_lmer, Satellite_lmer, Satellite_lm)
AICc(Satellite_All_lmer, Satellite_lmer, Satellite_lm)

# The mixed effects models is clearly preferred. However, the addition of PAR does not increase the accuracy of this model and should therefore not be considered.

```


# Checking model assumptions: Equal variance and normal distribution of model residuals:
```{r}

# Get the linear model residuals:
data$resid1 <- resid(Satellite_lmer)  
data$predict1 <- predict(Satellite_lmer) 

data$resid2 <- resid(Satellite_lm)  
data$predict2 <- predict(Satellite_lm) 

# Residual, Q-Q, Cooks distance plots:
plot(Satellite_lmer)  # Residuals
plot(Satellite_lm)

# Plot the distribution of the linear model residuals:
H_model1 <- ggplot(data = data, aes(resid1)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model2 <- ggplot(data = data, aes(resid2)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

ggarrange(H_model1, H_model2)


# Use the Shapiro-Wilks test to test for normality distributions in the residuals:
shapiro.test(data$resid1) 
shapiro.test(data$resid2) 

summary(Satellite_lmer)
summary(Satellite_lm)

```


# Perfrom a 25x cross validation to assess the accuracy of these models on new data. 
```{r}

# Containers for the predictions and accuracy measurements:

sample_train <- NULL

# Forward selections:
Sat_lmer_predict <- NULL
Sat_lmer_RMSE <- NULL
Sat_lmer_MAE <- NULL

Sat_lm_predict <- NULL
Sat_lm_RMSE <- NULL
Sat_lm_MAE <- NULL


# Loop through model prediction and perform 25x cross validation. 
# The model is trained on 95% of the data, and validated on the other 5%

for (i in 1:25) {
  
  #Creating a re-sampled data set from the total data:
  training.samples <- createDataPartition(data$TEP, p = 0.95, list = FALSE)
  train.data1  <- data[training.samples, ]  # Training set
  test.data1 <- data[-training.samples, ]  # Testing set
  
  
  # Running the models and creating predictions, accuracy metrics on the partitioned training data:
  
  # Remote mixed effects:
  Sat_lmer_CV<- lmer(TEP ~ Log_Chl + Temperature + POC + (1|Season), data = train.data1) 

  
  # Remote linear model:
  Sat_lm_CV<- lm(TEP ~ Log_Chl + Temperature + POC, data = train.data1) 
  
  
  # Model 'true' training points, applies to each model:
  sample_train <- c(sample_train, test.data1$TEP)
  
  
  
  # Model predictions and error calculations:
  
  # Mixed effects:
  Sat_lmer_predict <- c(Sat_lmer_predict, predict(Sat_lmer_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))  # Predictions
  
  Sat_lmer_RMSE <- c(Sat_lmer_RMSE, RMSE(Sat_lmer_predict, sample_train))  # RMSE
  
  Sat_lmer_MAE <- c(Sat_lmer_MAE, MAE(Sat_lmer_predict, sample_train))  # RMSE
  

  # Linear model:
  Sat_lm_predict <- c(Sat_lm_predict, predict(Sat_lm_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))  # Predictions
  
  Sat_lm_RMSE <- c(Sat_lm_RMSE, RMSE(Sat_lm_predict, sample_train))  # RMSE
  
  Sat_lm_MAE <- c(Sat_lm_MAE, MAE(Sat_lm_predict, sample_train))  # RMSE
}


# The above loop generated 25 different regression models with model coefficients, y intercepts and predictions, specified below for each of the models created: 

predictions <- cbind(remote_lmer_predict, remote_lm_predict)
predictions <- as.data.frame(predictions)  # as a data frame

```


# Plot the results of the cross validation:
```{r}

Sat_lmer_plot <- ggplot(predictions, aes(x = sample_train, y = Sat_lmer_predict)) +
    geom_point(alpha = 0.6, colour = "black") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    ggtitle("") +
    ylim(0, 175) +
    xlim(0, 175) +
    ylab("") +
    xlab("") +
    theme_pubr() +
    theme(plot.title=element_text(size=8,face="bold"))

Sat_lm_plot <- ggplot(predictions, aes(x = sample_train, y = Sat_lm_predict)) +
    geom_point(alpha = 0.6, colour = "black") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    ggtitle("") +
    ylim(0, 175) +
    xlim(0, 175) +
    ylab("") +
    xlab("") +
    theme_pubr() +
    theme(plot.title=element_text(size=8,face="bold"))

Figure <- ggarrange(Sat_lmer_plot, Sat_lm_plot)

Figure


```


# Print the mean aboslute errors and root mean square errors for both models:
```{r}

# Create data frames for the accuracy measurements:
RMSE <- cbind(Sat_lmer_RMSE, Sat_lm_RMSE)
RMSE <- as.data.frame(RMSE)

MAE <- cbind(Sat_lmer_MAE, Sat_lm_MAE)
MAE <- as.data.frame(MAE)

mean_total <- mean(data$TEP)  # Calculate mean of true values

# Get the average MAE and RMSE for each model:
MAE <- colMeans(MAE)
RMSE <- colMeans(RMSE)

print(MAE)
print(RMSE)

```