---
title: "Satellite_Sensor_Model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Upload required libraries:
```{r}

suppressMessages(library(ggplot2))
suppressMessages(library(caret))
suppressMessages(library(ggpubr))
suppressMessages(library(MuMIn))
suppressMessages(library(lme4))
suppressMessages(library(feather))
suppressMessages(library(arrow))
suppressMessages(library(dplyr))
suppressMessages(library(viridis))
suppressMessages(library(grid))
suppressMessages(library(car))
suppressMessages(library(GGally))
suppressMessages(library(reshape2))
suppressMessages(library(ggrepel))

```


# Upload all the data, and sort into workable dataframes:
```{r}

# Upload the data from a total data file:
total_data <- read.csv("Total_Sat_Data_All_Var.csv")

# Specify all the relevant variables:
data <- total_data %>% select(TEP, Temperature, Season, Log_Chl, POC, Avg_PAR, SST, Region)

```


# Step-wise Regressions models: Both forward and backward sequences for both types of models:
```{r}

# Define intercept-only model
intercept_only <- lm(TEP ~ 1, data = data)  # linear
intercept_lmer <- lmer(TEP ~ 1 + (1|Season), data = data)  # mixed effects

# Define model with all predictors
all <- lm(TEP ~ ., data = data)  # linear
all_lmer <- lmer(TEP ~ . + (1|Season), data = data)  # mixed effects

```



# Perform backward stepwise regression
```{r}

# Perform backward stepwise regression
backward <- step(all, direction ='backward', scope = formula(all), trace=0)
backward$anova
backward$coefficients

plot(backward$residuals ~ backward$fitted.values)


# Both model selection techniques coverged on the same set of variables, outlined below.
```



# Specify ideal mixed effects and linear models based on the variable selections above:
```{r}

# Base model:
base_model = lm(TEP ~ Log_Chl, data = data)

summary(base_model)
r.squaredGLMM(base_model)


# Model 2:
model_2 = lm(TEP ~ Temperature + Log_Chl, data = data)

summary(model_2)
r.squaredGLMM(model_2)


# Model 3:
model_3 = lm(TEP ~ Temperature + Log_Chl + POC, data = data)

summary(model_3)
r.squaredGLMM(model_3)


# Linear model:
Satellite_lm = lm(TEP ~ Temperature + Log_Chl + POC + Season, data = data)

summary(Satellite_lm)
r.squaredGLMM(Satellite_lm)



# Ideal satellite model:
Satellite_All_lmer = lmer(TEP ~ Temperature + Log_Chl + POC + (1|Season), data = data)

summary(Satellite_All_lmer)
r.squaredGLMM(Satellite_All_lmer)





```


# May need to eliminate variables to avoid multicollinearity:
```{r}


car::vif(model_2)
car::vif(model_3)


car::vif(Satellite_All_lmer)
car::vif(Satellite_lm)


# No concerns about multicollinearity....

```


# What model is prefferred? Check AIC and AICc:
```{r}

AIC(Satellite_All_lmer, Satellite_lm, base_model, model_2, model_3)
AICc(Satellite_All_lmer, Satellite_lm, base_model, model_2, model_3)

# The mixed effects models is clearly preferred. 

```


# Checking model assumptions: Equal variance and normal distribution of model residuals:
```{r}


# Get the model residuals:
data$resid1 <- resid(Satellite_All_lmer)  
data$predict1 <- predict(Satellite_All_lmer) 

data$resid2 <- resid(Satellite_lm)  
data$predict2 <- predict(Satellite_lm) 

data$resid3 <- resid(base_model)  
data$predict3 <- predict(base_model) 

data$resid4 <- resid(model_2)  
data$predict4 <- predict(model_2) 

data$resid5 <- resid(model_3)  
data$predict5 <- predict(model_3) 




# Residual, Q-Q, Cooks distance plots:
plot(Satellite_All_lmer)  # Residuals
plot(Satellite_lm)
plot(base_model)
plot(model_2)
plot(model_3)


# QQ plots:
Q_1 <- qqPlot(data$predict1, pch = 1)
Q_2 <- qqPlot(data$predict2, pch = 1)
Q_3 <- qqPlot(data$predict3, pch = 1)
Q_4 <- qqPlot(data$predict4, pch = 1)
Q_5 <- qqPlot(data$predict5, pch = 1)
```


# Check for normality in the residuals:
```{r}
# Plot the distribution of the linear model residuals:
H_model1 <- ggplot(data = data, aes(resid1)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model2 <- ggplot(data = data, aes(resid2)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model3 <- ggplot(data = data, aes(resid3)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model4 <- ggplot(data = data, aes(resid4)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()

H_model5 <- ggplot(data = data, aes(resid5)) + 
  geom_histogram(binwidth = 0.5, colour = "black", fill = "white") +
  xlab("Residuals") +
  ylab("Count") +
  theme_pubr()



ggarrange(H_model1, H_model2, H_model3, H_model4, H_model5)




# Use the Shapiro-Wilks test to test for normality distributions in the residuals:
shapiro.test(data$resid1) 
shapiro.test(data$resid2) 
shapiro.test(data$resid3) 
shapiro.test(data$resid4) 
shapiro.test(data$resid5) 

```


# Perfrom a 25x cross validation to assess the accuracy of these models on new data. 
```{r}

# Containers for the predictions and accuracy measurements:

sample_train <- NULL

# Forward selections:
Sat_lmer_predict <- NULL
Sat_lmer_RMSE <- NULL
Sat_lmer_MAE <- NULL

Sat_lm_predict <- NULL
Sat_lm_RMSE <- NULL
Sat_lm_MAE <- NULL

base_predict <- NULL
base_RMSE <- NULL
base_MAE <- NULL

model_2_predict <- NULL
model_2_RMSE <- NULL
model_2_MAE <- NULL

model_3_predict <- NULL
model_3_RMSE <- NULL
model_3_MAE <- NULL


# Loop through model prediction and perform 25x cross validation. 
# The model is trained on 95% of the data, and validated on the other 5%

for (i in 1:30) {
  
  #Creating a re-sampled data set from the total data:
  training.samples <- createDataPartition(data$TEP, p = 0.95, list = FALSE)
  train.data1  <- data[training.samples, ]  # Training set
  test.data1 <- data[-training.samples, ]  # Testing set
  
  
  # Running the models and creating predictions, accuracy metrics on the partitioned training data:
  
  # Ideal model::
  Sat_lmer_CV<- lmer(TEP ~ Log_Chl + Temperature + POC + (1|Season), data = train.data1) 

  # Linear model:
  Sat_lm_CV<- lm(TEP ~ Log_Chl + Temperature + POC, data = train.data1) 
  
  # Base model:
  base_CV<- lm(TEP ~ Log_Chl, data = train.data1) 
  
  # model 2:
  model_2_CV<- lm(TEP ~ Log_Chl + Temperature, data = train.data1) 
  
  # model 3:
  model_3_CV<- lm(TEP ~ Log_Chl + Temperature + POC, data = train.data1) 
  
  
  # Model 'true' training points, applies to each model:
  sample_train <- c(sample_train, test.data1$TEP)
  
  
  
  # Model predictions and error calculations:
  
  # Ideal model:
  Sat_lmer_predict <- c(Sat_lmer_predict, predict(Sat_lmer_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))  # Predictions
  
  Sat_lmer_RMSE <- c(Sat_lmer_RMSE, RMSE(Sat_lmer_predict, sample_train))  # RMSE
  
  Sat_lmer_MAE <- c(Sat_lmer_MAE, MAE(Sat_lmer_predict, sample_train))  # RMSE
  

  # Linear model:
  Sat_lm_predict <- c(Sat_lm_predict, predict(Sat_lm_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))  # Predictions
  
  Sat_lm_RMSE <- c(Sat_lm_RMSE, RMSE(Sat_lm_predict, sample_train))  # RMSE
  
  Sat_lm_MAE <- c(Sat_lm_MAE, MAE(Sat_lm_predict, sample_train))  # RMSE
  
  
  # Base model:
  base_predict <- c(base_predict, predict(base_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))  # Predictions
  
  base_RMSE <- c(base_RMSE, RMSE(base_predict, sample_train))  # RMSE
  
  base_MAE <- c(base_MAE, MAE(base_predict, sample_train))  # RMSE
  
  
  # Model 2:
  model_2_predict <- c(model_2_predict, predict(model_2_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))  # Predictions
  
  model_2_RMSE <- c(model_2_RMSE, RMSE(model_2_predict, sample_train))  # RMSE
  
  model_2_MAE <- c(model_2_MAE, MAE(model_2_predict, sample_train))  # RMSE
  
  
  # Model 3:
  model_3_predict <- c(model_3_predict, predict(model_3_CV, test.data1, 
                                                type = "response", allow.new.levels = TRUE))  # Predictions
  
  model_3_RMSE <- c(model_3_RMSE, RMSE(model_3_predict, sample_train))  # RMSE
  
  model_3_MAE <- c(model_3_MAE, MAE(model_3_predict, sample_train))  # RMSE
  
  
  
}


# The above loop generated 25 different regression models with model coefficients, y intercepts and predictions, specified below for each of the models created: 

predictions <- cbind(Sat_lmer_predict, Sat_lm_predict, base_predict, model_2_predict, model_3_predict)
predictions <- as.data.frame(predictions)  # as a data frame

```


# Plot the results of the cross validation:
```{r}

Figure <- ggplot(predictions, aes(x = sample_train)) +
    #geom_point(aes(y = Sat_lmer_predict), alpha = 0.6, colour = "blue") +
    geom_point(aes(y = Sat_lm_predict), alpha = 0.6, colour = "dodgerblue") +
    #geom_point(aes(y = Sat_lm_base_predict), alpha = 0.6, colour = "black") +
    geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
    ggtitle("") +
    ylim(0, 175) +
    xlim(0, 175) +
    ylab("") +
    xlab("") +
    theme_pubr() +
    theme(plot.title=element_text(size=8,face="bold"))


Figure

```


# Compare all the model accuracies with mean absolutew errors:
```{r, fig.width = 10, fig.height = 6}


# Get the MAE:
MAE <- cbind(base_MAE, model_2_MAE, model_3_MAE, Sat_lm_MAE, Sat_lmer_MAE)
MAE <- as.data.frame(MAE)
colnames(MAE) <- c('Chl','Chl + Temperature', 'Chl + Temperature + POC', 
                'Chl + Temperature + POC + Season', 'Chl + Temperature + POC + (1|Season)')

MAE_dff <- melt(MAE,  variable.name = 'MAE')


MAE <- colMeans(MAE)
print(MAE)

MAE_boxplot <- boxplot(base_MAE, model_2_MAE, model_3_MAE, Sat_lm_MAE, Sat_lmer_MAE, main='Mean Absolute Errors',
        names=c('Chl','Chl + Temperature', 'Chl + Temperature + POC', 
                'Chl + Temperature + POC + Season', 'Chl + Temperature + POC + (1|Season)'), outline=FALSE) +
        theme(axis.text.x = element_text(angle = 45, hjust = 0)) +
        coord_flip()



MAE_box <- ggplot(MAE_dff, aes(x = MAE, y = value)) +
  geom_boxplot(fill = "blue", alpha = 0.5) +
  ylab("Mean absolute error") +
  xlab("") +
  ylim(8, 17) +
  theme_pubr() +
  coord_flip()

MAE_box


pdf(file = "/Users/michaellivingston/Desktop/MAE.pdf",   # The directory you want to save the file in
    width = 11, # The width of the plot in inches
    height = 7) # The height of the plot in inches

MAE_box

dev.off()


# glmnet
```


# Now lets try predicting independent research expeditions:
```{r}

data <- total_data %>% select(TEP, Temperature, Season, Log_Chl, POC, Avg_PAR, SST, Region, Summer_2021_LP, Spring_2021_LP)


total_split_summer <- split(data, data$Summer_2021_LP) 
total_split_spring <- split(data, data$Spring_2021_LP)


data_summer_2021 <- total_split_summer$Y  
data_Else <- total_split_summer$N  


data_spring_2021 <- total_split_spring$Y  
data_Else2 <- total_split_spring$N 



Showcase_model_summer <- lm(TEP ~ Log_Chl + Temperature + POC + Season, data = data_Else)
Showcase_model_spring <- lm(TEP ~ Log_Chl + Temperature + POC + Season, data = data_Else2)


data_summer_2021$predict = predict(Showcase_model_summer, data_summer_2021, type = 'response')
data_Else$predict = predict(Showcase_model_summer, data_Else, type = 'response')


data_spring_2021$predict = predict(Showcase_model_spring, data_spring_2021, type = 'response')
data_Else2$predict = predict(Showcase_model_spring, data_Else, type = 'response')


Name = c("P1", "P4", "P12", "P16", "P20", "P26")

# Plot the results:

CV <- ggplot() +
  
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  
  geom_point(aes(x = data_Else$TEP, y = data_Else$predict), colour = 'black', alpha = 0.3) + 

  geom_point(aes(x = data_spring_2021$TEP, data_spring_2021$predict), colour = 'blue', fill = 'blue', shape = 23) +
  
  geom_label_repel(aes(x = data_spring_2021$TEP, data_spring_2021$predict, label = Name),
                  box.padding   = 0.15, 
                  point.padding = 0.15,
                  segment.linetype = 1,
                  segment.color = 'blue', 
                  max.overlaps = Inf) +


  theme_classic() +
  xlab("Measured TEP") +
  ylab("Predicted TEP") +
  ylim(0, 160) +
  xlim(0, 160)
  

pdf(file = "/Users/michaellivingston/Desktop/CV.pdf",   # The directory you want to save the file in
    width = 11, # The width of the plot in inches
    height = 7) # The height of the plot in inches

CV

dev.off()


```






